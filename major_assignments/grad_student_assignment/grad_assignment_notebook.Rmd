---
title: "Grad Student Assignment"
author: "Cait Kelley"
date: "12/3/2023"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this notebook, I'm looking at violent crime and property crime stats in Maryland: <https://opendata.maryland.gov/Public-Safety/Violent-Crime-Property-Crime-by-County-1975-to-Pre/jwfa-fdxs>

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(tidycensus)
library(janitor)
```

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data.

This dataset contains data about violent and property crimes in Maryland between 1975 and 2020.

1975 is missing percent change data because they can't compare that year's data to 1974's data. No other year is missing percent change data.

Other questions to answer in this notebook:

-Who created and maintains the data?

"The data are provided are the Maryland Statistical Analysis Center (MSAC), within the Governor's Office of Crime Control and Prevention (GOCCP). MSAC, in turn, receives these data from the Maryland State Police's annual Uniform Crime Reports." -<https://opendata.maryland.gov/Public-Safety/Violent-Crime-Property-Crime-by-County-1975-to-Pre/jwfa-fdxs>

The Department of Information Technology updates the data.

-What state program or law is connected to it?

Crime statistics are supposed to be submitted to the state of Maryland and to the FBI accoring to UCI (Uniform Crime Reporting) standards.

-What does each row represent?

The dataset has 1,104 rows which represent yearly stats for every county. However, a few rows are not in chronological order, but I did check and every jurisdiction has data for all 46 years.

-What is the chronological and geographic scope of this data?

The data goes from 1975 to 2020. Not sure why there isn't more recent data. It shows jurisdiction/county data.

-If this data contains aggregates (totals), can you find itemized data that those totals are derived from?

Yes.

-Do the totals match your own calculations using the itemized data?

Yes.

```{r}
# Load required data
violent_and_property_crime_md <- read_csv("data/violent_crime_property_crime_by_county_1975_to_present.csv")


# Clean required data and prepare for analysis if needed.
violent_and_property_crime_md <- violent_and_property_crime_md |>
  clean_names()

# checking if each county has data for every year
violent_and_property_crime_md |>
  group_by(jurisdiction) |>
  summarise(total = n())

# looking at the NAs in 1975 that I noticed
violent_and_property_crime_md |>
 filter(year==1975)

# checking to see if there are any NAs in other years. There aren't
any_na_values <- violent_and_property_crime_md %>%
  filter_all(any_vars(is.na(.)))
  #chatGPT helped with this

# looking at some crime trends over the years
violent_and_property_crime_md |>
  group_by(year) |>
  summarise(total = sum(murder_per_100_000_people))


# graphing overall crime rate over the years to pick out trends 
violent_and_property_crime_md |>
  ggplot() +
  geom_bar(aes(x=year, weight=violent_crime_rate_per_100_000_people)) +
labs(
    x = "Year",
    y = "Violent Crimes per 100,000 people")

#checking if math adds up to totals
violent_and_property_crime_md_check <-violent_and_property_crime_md |>
  mutate(grand_total_checked = murder + rape + robbery + agg_assault + b_e + larceny_theft + m_v_theft) |>
  select(grand_total, grand_total_checked)
#I tried using get_dupes to check if the columns were the same but it didn't do what I wanted so I asked ChatGPT how to check if two columns are exactly the same:

violent_and_property_crime_md_check <- violent_and_property_crime_md_check |>
 mutate(columns_match = if_else(grand_total == grand_total_checked, TRUE, FALSE))

violent_and_property_crime_md_check |>
  filter(str_detect(columns_match, "TRUE"))
# 1,104 rows say TRUE which means there are no rows that don't match. All the totals add up.

```

## Story Ideas

In this notebook, I am exploring three potential story ideas.

### Story Idea 1

-   **Sentence text**: Can I see the so called Freddie Gray Effect on crime stats in Baltimore when I compare their stats to the state as a whole? 

The idea of the Freddie Gray Effect (https://www.usatoday.com/story/news/nation/2018/07/12/baltimore-police-not-noticing-crime-after-freddie-gray-wave-killings-followed/744741002/) is that police stopped proactively fighting crime after the killing of Freddie Gray (April 12, 2015) and subsequent protests against police and Obama administrations investigations into police departments. And then there was a wave of violent crime. This dataset doesn't have monthly stats, but I wonder if serious violent crimes went up in the year(s) after his murder in Baltimore, especially compared to Maryland as a whole.  

-   **Analysis summary**: Looks like the statewide murder rate was at an all-time low in 2014 and then shot up for a few years starting in 2015. I then removed Baltimore City from the overall state data to truly compare the city and the rest of the state. You can see a much clearer downward trend in the murder rate in Maryland over time if you remove the Baltimore City data. This seems to back up what other data investigations have found. It's interesting that it looks like the murder rate has trended upward in Balitmore, in contrast to the rest of the state, in general over time not just in 2015.

Overall however, the murder rate appears to have been much higher in the state as a whole compared to Baltimore City over time. I don't know if calculating the rate per 100,000 people could be affecting that because the numbers just get so small, or if that's just true. If I were to completely report out this story I'd check that.

I calculated the percent change (based on the murder rate percent change column in the dataset) in the murder rates. The percent change in murders per 100,000 people in Baltimore City from 2014-2015 was 63.6 and 971.8 for the remaining counties in total, but I think I have to divide that number by 23 which equals 42.3. In which case the rate of change in Baltimore City was higher than the other counties.

I think the Freddie Gray Effect of increased murders in Baltimore since 2015 can be seen in this statewide yearly crime statistics. I'd like to see the crime stats since 2020 to see if this trend continued. When those come out that's a potential story as well.

```{r}
# Put code here
# Comparing murder rates per capita in Baltimore City and Maryland as a whole over time
violent_and_property_crime_md |>
  ggplot() +
  geom_bar(aes(x=year, weight=murder_per_100_000_people)) +
labs(
  title = "Murder rate in Maryland, 1975-2020",
    x = "Year",
    y = "Murders per 100,000 people")


# Make a dataset without Baltimore City

violent_and_property_crime_wo_bc <- violent_and_property_crime_md |>
  filter(jurisdiction != "Baltimore City")

# Graph statewide data again without Baltimore City

violent_and_property_crime_wo_bc |>
  ggplot() +
  geom_bar(aes(x=year, weight=murder_per_100_000_people)) +
labs(
  title = "Murder rate in Maryland Not Counting Baltimore City, 1975-2020",
    x = "Year",
    y = "Murders per 100,000 people")

# rate of change between 2014 and 2015 for statewide minus BC

violent_and_property_crime_wo_bc |>
  filter(year == "2015") |>
  select(jurisdiction, year, murder_per_100_000_people, murder_rate_percent_change_per_100_000_people) |>
  group_by(year) |>
  summarise(total_percent_change = sum(murder_rate_percent_change_per_100_000_people))

# Pull out Baltimore City data

violent_and_property_crime_bc <- violent_and_property_crime_md |>
  filter(jurisdiction == "Baltimore City")

# rate of change 2014-2015 BC

violent_and_property_crime_bc |>
  filter(year == "2015") |>
   select(jurisdiction, year, murder_per_100_000_people, murder_rate_percent_change_per_100_000_people) |>
  group_by(year) |>
  summarise(total_percent_change = sum(murder_rate_percent_change_per_100_000_people))

# Graph Baltimore City data

violent_and_property_crime_bc |>
  ggplot() +
  geom_bar(aes(x=year, weight=murder_per_100_000_people)) +
labs(
  title = "Murder rate in Baltimore City, 1975-2020",
    x = "Year",
    y = "Murders per 100,000 people")


# Display results of code below this codeblock

```

### Story Idea 2

-   **Sentence text**: Which counties in Maryland experienced the biggest percent change in violent crime in 2020 and what are the demographics of those counties?
-   **Analysis summary**: I used the Maryland demographics dataset that we already had from pre lab 6. It should be relatively similar to 2020 demographics. I'll join that with the crime data.

```{r}
# Put code here

# Loaded demographic data from pre lab 6 and cleaned it

# ChatGPT helped me figure out how to add county back to the names
md_demographics <- read_csv("data/maryland_demographics.csv") |>
  clean_names() |>
  rename(jurisdiction = name) |>
   mutate(jurisdiction = if_else(jurisdiction %in% c("Baltimore City", "Baltimore County"), 
                                 jurisdiction, 
                                 paste(jurisdiction, "County", sep = " ")))


murder_total_violent_crime_md <- violent_and_property_crime_md |>
  filter(year == "2020") |>
  select(jurisdiction, year, population, murder, murder_per_100_000_people, murder_rate_percent_change_per_100_000_people, violent_crime_total, violent_crime_rate_per_100_000_people, violent_crime_rate_percent_change_per_100_000_people )

murder_violent_crime_demographics_md <- murder_total_violent_crime_md |>
  left_join(md_demographics, join_by("jurisdiction")) |>
  select(-geocode, -pop_one_race, -pop_other, -pop_two_more)
 

# Display results of code below this codeblock

```

### Story Idea 3

-   **Sentence text**: How does the unemployment rate map onto violent crime in Baltimore? Could that explain crime in Baltimore better than the Freddie Gray Effect or Covid-19?

-   **Analysis summary**: [Write up two to three sentences describing the results of your analysis. Were you able to confirm the finding? If not, why not?]

```{r}
# Put code here
# I found unemployment rate data for Maryland between 1990 and 2020 here: https://msa.maryland.gov/msa/mdmanual/01glance/economy/html/unemployrates.html#:~:text=In%20October%202023%2C%20Maryland's%20unemployment,employed%20and%2055%2C437%20were%20unemployed.

#There wasn't data by county before 1990

# I made a Google spreadsheet by copying and pasting the relevant data and will read that in as a csv now

unemployment_rate_md_1990_2020 <- read_csv("data/unemployment_rate_md_1990_2020.csv") |>
  rename(county = "...1")

unemployment_bc <-unemployment_rate_md_1990_2020 |>
  filter(county == "Baltimore City")

# reorganize the dataset with help from chat GPT

unemployment_bc_long <- unemployment_bc %>%
  gather(key = "year", value = "crime_rate", -county) %>%
  mutate(year = as.integer(year))

# Line graph of unemployment rates in Baltimore City over time

ggplot(unemployment_bc_long, aes(x = year, y = crime_rate, color = county)) +
  geom_line() +
  labs(title = "Baltimore City Unemployment Rate, 1990-2020",
       x = "Year",
       y = "Crime Rate",
       color = "County")

# Make a dataframe


#ggplot() +
#  geom_line(data = unemployment_bc_long, aes(x = year, y = crime_rate, color = county)) +
#  geom_bar(data = bar_data_long, aes(x = Year, y = BarValue, fill = county),
 #          stat = "identity", position = "dodge") +
 # labs(title = "Overlay of Line Graph and Bar Chart",
 #      x = "Year",
 #      y = "Value")

# Display results of code below this codeblock

```
